import os
import numpy as np
import tempfile, zipfile
import torch
import torch.nn as nn
import torch.nn.functional as F
try:
    import torchvision
except:
    pass

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()

        self.features_0 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=3, kernel_size=(3,3), out_channels=64, padding=(0,0), padding_mode='zeros', stride=(2,2))
        self.features_1 = nn.ReLU()
        self.features_2 = nn.MaxPool2d(ceil_mode=True, dilation=(1,1), kernel_size=(3,3), padding=(0,0), return_indices=False, stride=(2,2))
        self.features_3_squeeze = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=64, kernel_size=(1,1), out_channels=16, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.features_3_squeeze_activation = nn.ReLU()
        self.features_3_expand1x1 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=16, kernel_size=(1,1), out_channels=64, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.features_3_expand1x1_activation = nn.ReLU()
        self.features_3_expand3x3 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=16, kernel_size=(3,3), out_channels=64, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.features_3_expand3x3_activation = nn.ReLU()
        self.features_4_squeeze = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=128, kernel_size=(1,1), out_channels=16, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.features_4_squeeze_activation = nn.ReLU()
        self.features_4_expand1x1 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=16, kernel_size=(1,1), out_channels=64, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.features_4_expand1x1_activation = nn.ReLU()
        self.features_4_expand3x3 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=16, kernel_size=(3,3), out_channels=64, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.features_4_expand3x3_activation = nn.ReLU()
        self.features_5 = nn.MaxPool2d(ceil_mode=True, dilation=(1,1), kernel_size=(3,3), padding=(0,0), return_indices=False, stride=(2,2))
        self.features_6_squeeze = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=128, kernel_size=(1,1), out_channels=32, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.features_6_squeeze_activation = nn.ReLU()
        self.features_6_expand1x1 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=32, kernel_size=(1,1), out_channels=128, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.features_6_expand1x1_activation = nn.ReLU()
        self.features_6_expand3x3 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=32, kernel_size=(3,3), out_channels=128, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.features_6_expand3x3_activation = nn.ReLU()
        self.features_7_squeeze = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=256, kernel_size=(1,1), out_channels=32, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.features_7_squeeze_activation = nn.ReLU()
        self.features_7_expand1x1 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=32, kernel_size=(1,1), out_channels=128, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.features_7_expand1x1_activation = nn.ReLU()
        self.features_7_expand3x3 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=32, kernel_size=(3,3), out_channels=128, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.features_7_expand3x3_activation = nn.ReLU()
        self.features_8 = nn.MaxPool2d(ceil_mode=True, dilation=(1,1), kernel_size=(3,3), padding=(0,0), return_indices=False, stride=(2,2))
        self.features_9_squeeze = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=256, kernel_size=(1,1), out_channels=48, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.features_9_squeeze_activation = nn.ReLU()
        self.features_9_expand1x1 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=48, kernel_size=(1,1), out_channels=192, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.features_9_expand1x1_activation = nn.ReLU()
        self.features_9_expand3x3 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=48, kernel_size=(3,3), out_channels=192, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.features_9_expand3x3_activation = nn.ReLU()
        self.features_10_squeeze = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=384, kernel_size=(1,1), out_channels=48, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.features_10_squeeze_activation = nn.ReLU()
        self.features_10_expand1x1 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=48, kernel_size=(1,1), out_channels=192, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.features_10_expand1x1_activation = nn.ReLU()
        self.features_10_expand3x3 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=48, kernel_size=(3,3), out_channels=192, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.features_10_expand3x3_activation = nn.ReLU()
        self.features_11_squeeze = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=384, kernel_size=(1,1), out_channels=64, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.features_11_squeeze_activation = nn.ReLU()
        self.features_11_expand1x1 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=64, kernel_size=(1,1), out_channels=256, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.features_11_expand1x1_activation = nn.ReLU()
        self.features_11_expand3x3 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=64, kernel_size=(3,3), out_channels=256, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.features_11_expand3x3_activation = nn.ReLU()
        self.features_12_squeeze = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=512, kernel_size=(1,1), out_channels=64, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.features_12_squeeze_activation = nn.ReLU()
        self.features_12_expand1x1 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=64, kernel_size=(1,1), out_channels=256, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.features_12_expand1x1_activation = nn.ReLU()
        self.features_12_expand3x3 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=64, kernel_size=(3,3), out_channels=256, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.features_12_expand3x3_activation = nn.ReLU()
        self.classifier_1 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=512, kernel_size=(1,1), out_channels=1000, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.classifier_2 = nn.ReLU()
        self.classifier_3 = nn.AdaptiveAvgPool2d(output_size=(1,1))

        archive = zipfile.ZipFile('squeezenet_v1.1.pnnx.bin', 'r')
        self.features_0.bias = self.load_pnnx_bin_as_parameter(archive, 'features.0.bias', (64), 'float32')
        self.features_0.weight = self.load_pnnx_bin_as_parameter(archive, 'features.0.weight', (64,3,3,3), 'float32')
        self.features_3_squeeze.bias = self.load_pnnx_bin_as_parameter(archive, 'features.3.squeeze.bias', (16), 'float32')
        self.features_3_squeeze.weight = self.load_pnnx_bin_as_parameter(archive, 'features.3.squeeze.weight', (16,64,1,1), 'float32')
        self.features_3_expand1x1.bias = self.load_pnnx_bin_as_parameter(archive, 'features.3.expand1x1.bias', (64), 'float32')
        self.features_3_expand1x1.weight = self.load_pnnx_bin_as_parameter(archive, 'features.3.expand1x1.weight', (64,16,1,1), 'float32')
        self.features_3_expand3x3.bias = self.load_pnnx_bin_as_parameter(archive, 'features.3.expand3x3.bias', (64), 'float32')
        self.features_3_expand3x3.weight = self.load_pnnx_bin_as_parameter(archive, 'features.3.expand3x3.weight', (64,16,3,3), 'float32')
        self.features_4_squeeze.bias = self.load_pnnx_bin_as_parameter(archive, 'features.4.squeeze.bias', (16), 'float32')
        self.features_4_squeeze.weight = self.load_pnnx_bin_as_parameter(archive, 'features.4.squeeze.weight', (16,128,1,1), 'float32')
        self.features_4_expand1x1.bias = self.load_pnnx_bin_as_parameter(archive, 'features.4.expand1x1.bias', (64), 'float32')
        self.features_4_expand1x1.weight = self.load_pnnx_bin_as_parameter(archive, 'features.4.expand1x1.weight', (64,16,1,1), 'float32')
        self.features_4_expand3x3.bias = self.load_pnnx_bin_as_parameter(archive, 'features.4.expand3x3.bias', (64), 'float32')
        self.features_4_expand3x3.weight = self.load_pnnx_bin_as_parameter(archive, 'features.4.expand3x3.weight', (64,16,3,3), 'float32')
        self.features_6_squeeze.bias = self.load_pnnx_bin_as_parameter(archive, 'features.6.squeeze.bias', (32), 'float32')
        self.features_6_squeeze.weight = self.load_pnnx_bin_as_parameter(archive, 'features.6.squeeze.weight', (32,128,1,1), 'float32')
        self.features_6_expand1x1.bias = self.load_pnnx_bin_as_parameter(archive, 'features.6.expand1x1.bias', (128), 'float32')
        self.features_6_expand1x1.weight = self.load_pnnx_bin_as_parameter(archive, 'features.6.expand1x1.weight', (128,32,1,1), 'float32')
        self.features_6_expand3x3.bias = self.load_pnnx_bin_as_parameter(archive, 'features.6.expand3x3.bias', (128), 'float32')
        self.features_6_expand3x3.weight = self.load_pnnx_bin_as_parameter(archive, 'features.6.expand3x3.weight', (128,32,3,3), 'float32')
        self.features_7_squeeze.bias = self.load_pnnx_bin_as_parameter(archive, 'features.7.squeeze.bias', (32), 'float32')
        self.features_7_squeeze.weight = self.load_pnnx_bin_as_parameter(archive, 'features.7.squeeze.weight', (32,256,1,1), 'float32')
        self.features_7_expand1x1.bias = self.load_pnnx_bin_as_parameter(archive, 'features.7.expand1x1.bias', (128), 'float32')
        self.features_7_expand1x1.weight = self.load_pnnx_bin_as_parameter(archive, 'features.7.expand1x1.weight', (128,32,1,1), 'float32')
        self.features_7_expand3x3.bias = self.load_pnnx_bin_as_parameter(archive, 'features.7.expand3x3.bias', (128), 'float32')
        self.features_7_expand3x3.weight = self.load_pnnx_bin_as_parameter(archive, 'features.7.expand3x3.weight', (128,32,3,3), 'float32')
        self.features_9_squeeze.bias = self.load_pnnx_bin_as_parameter(archive, 'features.9.squeeze.bias', (48), 'float32')
        self.features_9_squeeze.weight = self.load_pnnx_bin_as_parameter(archive, 'features.9.squeeze.weight', (48,256,1,1), 'float32')
        self.features_9_expand1x1.bias = self.load_pnnx_bin_as_parameter(archive, 'features.9.expand1x1.bias', (192), 'float32')
        self.features_9_expand1x1.weight = self.load_pnnx_bin_as_parameter(archive, 'features.9.expand1x1.weight', (192,48,1,1), 'float32')
        self.features_9_expand3x3.bias = self.load_pnnx_bin_as_parameter(archive, 'features.9.expand3x3.bias', (192), 'float32')
        self.features_9_expand3x3.weight = self.load_pnnx_bin_as_parameter(archive, 'features.9.expand3x3.weight', (192,48,3,3), 'float32')
        self.features_10_squeeze.bias = self.load_pnnx_bin_as_parameter(archive, 'features.10.squeeze.bias', (48), 'float32')
        self.features_10_squeeze.weight = self.load_pnnx_bin_as_parameter(archive, 'features.10.squeeze.weight', (48,384,1,1), 'float32')
        self.features_10_expand1x1.bias = self.load_pnnx_bin_as_parameter(archive, 'features.10.expand1x1.bias', (192), 'float32')
        self.features_10_expand1x1.weight = self.load_pnnx_bin_as_parameter(archive, 'features.10.expand1x1.weight', (192,48,1,1), 'float32')
        self.features_10_expand3x3.bias = self.load_pnnx_bin_as_parameter(archive, 'features.10.expand3x3.bias', (192), 'float32')
        self.features_10_expand3x3.weight = self.load_pnnx_bin_as_parameter(archive, 'features.10.expand3x3.weight', (192,48,3,3), 'float32')
        self.features_11_squeeze.bias = self.load_pnnx_bin_as_parameter(archive, 'features.11.squeeze.bias', (64), 'float32')
        self.features_11_squeeze.weight = self.load_pnnx_bin_as_parameter(archive, 'features.11.squeeze.weight', (64,384,1,1), 'float32')
        self.features_11_expand1x1.bias = self.load_pnnx_bin_as_parameter(archive, 'features.11.expand1x1.bias', (256), 'float32')
        self.features_11_expand1x1.weight = self.load_pnnx_bin_as_parameter(archive, 'features.11.expand1x1.weight', (256,64,1,1), 'float32')
        self.features_11_expand3x3.bias = self.load_pnnx_bin_as_parameter(archive, 'features.11.expand3x3.bias', (256), 'float32')
        self.features_11_expand3x3.weight = self.load_pnnx_bin_as_parameter(archive, 'features.11.expand3x3.weight', (256,64,3,3), 'float32')
        self.features_12_squeeze.bias = self.load_pnnx_bin_as_parameter(archive, 'features.12.squeeze.bias', (64), 'float32')
        self.features_12_squeeze.weight = self.load_pnnx_bin_as_parameter(archive, 'features.12.squeeze.weight', (64,512,1,1), 'float32')
        self.features_12_expand1x1.bias = self.load_pnnx_bin_as_parameter(archive, 'features.12.expand1x1.bias', (256), 'float32')
        self.features_12_expand1x1.weight = self.load_pnnx_bin_as_parameter(archive, 'features.12.expand1x1.weight', (256,64,1,1), 'float32')
        self.features_12_expand3x3.bias = self.load_pnnx_bin_as_parameter(archive, 'features.12.expand3x3.bias', (256), 'float32')
        self.features_12_expand3x3.weight = self.load_pnnx_bin_as_parameter(archive, 'features.12.expand3x3.weight', (256,64,3,3), 'float32')
        self.classifier_1.bias = self.load_pnnx_bin_as_parameter(archive, 'classifier.1.bias', (1000), 'float32')
        self.classifier_1.weight = self.load_pnnx_bin_as_parameter(archive, 'classifier.1.weight', (1000,512,1,1), 'float32')
        archive.close()

    def load_pnnx_bin_as_parameter(self, archive, key, shape, dtype, requires_grad=True):
        return nn.Parameter(self.load_pnnx_bin_as_tensor(archive, key, shape, dtype), requires_grad)

    def load_pnnx_bin_as_tensor(self, archive, key, shape, dtype):
        fd, tmppath = tempfile.mkstemp()
        with os.fdopen(fd, 'wb') as tmpf, archive.open(key) as keyfile:
            tmpf.write(keyfile.read())
        m = np.memmap(tmppath, dtype=dtype, mode='r', shape=shape).copy()
        os.remove(tmppath)
        return torch.from_numpy(m)

    def forward(self, v_0):
        v_1 = self.features_0(v_0)
        v_2 = self.features_1(v_1)
        v_3 = self.features_2(v_2)
        v_4 = self.features_3_squeeze(v_3)
        v_5 = self.features_3_squeeze_activation(v_4)
        v_6 = self.features_3_expand1x1(v_5)
        v_7 = self.features_3_expand1x1_activation(v_6)
        v_8 = self.features_3_expand3x3(v_5)
        v_9 = self.features_3_expand3x3_activation(v_8)
        v_10 = torch.cat((v_7, v_9), dim=1)
        v_11 = self.features_4_squeeze(v_10)
        v_12 = self.features_4_squeeze_activation(v_11)
        v_13 = self.features_4_expand1x1(v_12)
        v_14 = self.features_4_expand1x1_activation(v_13)
        v_15 = self.features_4_expand3x3(v_12)
        v_16 = self.features_4_expand3x3_activation(v_15)
        v_17 = torch.cat((v_14, v_16), dim=1)
        v_18 = self.features_5(v_17)
        v_19 = self.features_6_squeeze(v_18)
        v_20 = self.features_6_squeeze_activation(v_19)
        v_21 = self.features_6_expand1x1(v_20)
        v_22 = self.features_6_expand1x1_activation(v_21)
        v_23 = self.features_6_expand3x3(v_20)
        v_24 = self.features_6_expand3x3_activation(v_23)
        v_25 = torch.cat((v_22, v_24), dim=1)
        v_26 = self.features_7_squeeze(v_25)
        v_27 = self.features_7_squeeze_activation(v_26)
        v_28 = self.features_7_expand1x1(v_27)
        v_29 = self.features_7_expand1x1_activation(v_28)
        v_30 = self.features_7_expand3x3(v_27)
        v_31 = self.features_7_expand3x3_activation(v_30)
        v_32 = torch.cat((v_29, v_31), dim=1)
        v_33 = self.features_8(v_32)
        v_34 = self.features_9_squeeze(v_33)
        v_35 = self.features_9_squeeze_activation(v_34)
        v_36 = self.features_9_expand1x1(v_35)
        v_37 = self.features_9_expand1x1_activation(v_36)
        v_38 = self.features_9_expand3x3(v_35)
        v_39 = self.features_9_expand3x3_activation(v_38)
        v_40 = torch.cat((v_37, v_39), dim=1)
        v_41 = self.features_10_squeeze(v_40)
        v_42 = self.features_10_squeeze_activation(v_41)
        v_43 = self.features_10_expand1x1(v_42)
        v_44 = self.features_10_expand1x1_activation(v_43)
        v_45 = self.features_10_expand3x3(v_42)
        v_46 = self.features_10_expand3x3_activation(v_45)
        v_47 = torch.cat((v_44, v_46), dim=1)
        v_48 = self.features_11_squeeze(v_47)
        v_49 = self.features_11_squeeze_activation(v_48)
        v_50 = self.features_11_expand1x1(v_49)
        v_51 = self.features_11_expand1x1_activation(v_50)
        v_52 = self.features_11_expand3x3(v_49)
        v_53 = self.features_11_expand3x3_activation(v_52)
        v_54 = torch.cat((v_51, v_53), dim=1)
        v_55 = self.features_12_squeeze(v_54)
        v_56 = self.features_12_squeeze_activation(v_55)
        v_57 = self.features_12_expand1x1(v_56)
        v_58 = self.features_12_expand1x1_activation(v_57)
        v_59 = self.features_12_expand3x3(v_56)
        v_60 = self.features_12_expand3x3_activation(v_59)
        v_61 = torch.cat((v_58, v_60), dim=1)
        v_62 = self.classifier_1(v_61)
        v_63 = self.classifier_2(v_62)
        v_64 = self.classifier_3(v_63)
        v_65 = torch.flatten(input=v_64, end_dim=-1, start_dim=1)
        return v_65

def export_torchscript():
    net = Model()
    net.eval()

    torch.manual_seed(0)
    v_0 = torch.rand(1, 3, 227, 227, dtype=torch.float)

    mod = torch.jit.trace(net, v_0)
    mod.save("squeezenet_v1.1_pnnx.py.pt")

def export_onnx():
    net = Model()
    net.eval()

    torch.manual_seed(0)
    v_0 = torch.rand(1, 3, 227, 227, dtype=torch.float)

    torch.onnx._export(net, v_0, "squeezenet_v1.1_pnnx.py.onnx", export_params=True, operator_export_type=torch.onnx.OperatorExportTypes.ONNX_ATEN_FALLBACK, opset_version=13, input_names=['in0'], output_names=['out0'])

def test_inference():
    net = Model()
    net.eval()

    torch.manual_seed(0)
    v_0 = torch.rand(1, 3, 227, 227, dtype=torch.float)

    return net(v_0)

if __name__ == "__main__":
    print(test_inference())
